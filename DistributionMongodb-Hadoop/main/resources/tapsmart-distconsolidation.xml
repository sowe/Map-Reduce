<?xml version="1.0"?> 
<configuration>
  <property>
    <name>mongo.job.name</name>
    <value>Distribution Consolidator</value>
  </property>
  <property>
    <!-- run the job verbosely ? -->
    <name>mongo.job.verbose</name>
    <value>true</value>
  </property>
  <property>
    <!-- Run the job in the foreground and wait for response, or background it? -->
    <name>mongo.job.background</name>
    <value>false</value>
  </property>
  <property>
      <!-- The field to pass as the mapper key. Defaults to _id if blank -->
      <name>mongo.input.key</name>
      <value></value>
  </property>
  <property>
    <!-- The query, in JSON, to execute [OPTIONAL] -->
    <name>mongo.input.query</name>
    <!--<value>{"x": {"$regex": "^eliot", "$options": ""}}</value>-->
    <value></value>
  </property>
  <property>
    <!-- The fields, in JSON, to read [OPTIONAL] -->
    <name>mongo.input.fields</name>
    <value></value>
  </property>
  <property>
    <!-- A JSON sort specification for read [OPTIONAL] -->
    <name>mongo.input.sort</name>
    <value></value>
  </property>
  <property>
    <!-- The number of documents to limit to for read [OPTIONAL] -->
    <name>mongo.input.limit</name>
    <value>0</value> <!-- 0 == no limit -->
  </property>
  <property>
    <!-- The number of documents to skip in read [OPTIONAL] -->
    <!-- TODO - Are we running limit() or skip() first? -->
    <name>mongo.input.skip</name>
    <value>0</value> <!-- 0 == no skip -->
  </property>
  <property>
    <!-- InputFormat Class -->
    <name>mongo.job.input.format</name>
    <value>com.mongodb.hadoop.MongoInputFormat</value>
  </property>
  <property>
    <!-- OutputFormat Class -->
    <name>mongo.job.output.format</name>
    <value>com.mongodb.hadoop.MongoOutputFormat</value> 
  </property>
  <property>
    <!-- Output key class for the output format -->
    <name>mongo.job.output.key</name>
    <value>com.mongodb.hadoop.io.BSONWritable</value>
  </property>
  <property>
    <!-- Output value class for the output format -->
    <name>mongo.job.output.value</name>
    <value>com.mongodb.hadoop.io.BSONWritable</value>
  </property>
  <property>
    <!-- Output key class for the mapper [optional] -->
    <name>mongo.job.mapper.output.key</name>
    <value></value>
    <value>com.mongodb.hadoop.io.BSONWritable</value>
  </property>
  <property>
    <!-- Output value class for the mapper [optional] -->
    <name>mongo.job.mapper.output.value</name>
    <value>com.mongodb.hadoop.io.BSONWritable</value>
  </property>
  <property>
    <!-- Class for the combiner [optional] -->
    <name>mongo.job.combiner</name>
    <value></value>
  </property>
  <property>
    <!-- Partitioner class [optional] -->
    <name>mongo.job.partitioner</name>
    <value></value>
  </property>
  <property>
    <!-- Sort Comparator class [optional] -->
    <name>mongo.job.sort_comparator</name>
    <value></value>
  </property>
  <property>
    <!-- If you are writing to mongo, the URI -->
    <name>mongo.input.uri</name>
    <value>mongodb://ec2-176-34-166-149.eu-west-1.compute.amazonaws.com/tapsmart.tmp.distributions</value>
  </property>
  <property>
    <!-- If you are writing to mongo, the URI -->
    <name>mongo.output.uri</name>
    <value>mongodb://ec2-176-34-166-149.eu-west-1.compute.amazonaws.com/tapsmart.distributions</value>
  </property>
  <property>
    <!-- Class for the mapper -->
    <name>mongo.job.mapper</name>
    <value>com.tapsmart.hadoop.mapper.DistributionConsolidationMapper</value>
  </property>
  <property>
    <!-- Reducer class -->
    <name>mongo.job.reducer</name>
    <value>com.tapsmart.hadoop.reducer.DistributionConsolidationReducer</value>
  </property>
</configuration>
